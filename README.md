<p align="center">
  <img src="assets/Credit_img.png" alt="Project Banner" width="100%">
</p>


![Python version](https://img.shields.io/badge/Python%20version-3.10%2B-lightgrey)
![GitHub repo size](https://img.shields.io/github/repo-size/coder-red/credit-risk-model)
![GitHub last commit](https://img.shields.io/github/last-commit/coder-red/credit-risk-model)
![Type of ML](https://img.shields.io/badge/Type%20of%20ML-Binary%20Classification-red)
[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://credit-risk-model-demo.streamlit.app/)



# Key findings: Borrowers asking for a higher loan amount and those having existing debt burdens were significantly more likely to default. 

## Author

- [@coder-red](https://www.github.com/coder-red)

## Table of Contents

  - [Borrowers asking for a higher loan amount and those having existing debt burdens were significantly more likely to default](#Borrowers-asking-for-a-higher-loan-amount-and-those-having-existing-debt-burdens-were-significantly-more-likely-to-default)

  - [Author](#author)
  - [Table of Contents](#table-of-contents)
  - [Business Context](#business-context)
  - [Data source](#data-source)
  - [Methods](#methods)
  - [Live Demo](#live-demo)
  - [Tech Stack](#tech-stack)
  - [Quick glance at the results](#quick-glance-at-the-results)
  - [Lessons learned and recommendation](#lessons-learned-and-recommendation)
  - [Limitation and what can be improved](#limitation-and-what-can-be-improved)
  - [Repository structure](#repository-structure)


## Business Context

This model predicts if a borrower will pay back a loan or not. Lending institutions use this to make informed decisions on whether to approve a loan or not, manage credit risks, and reduce default related losses.

## Data source

- [Kaggle Home Credit Default Risk](https://www.kaggle.com/competitions/home-credit-default-risk/data)


## Methods

- Data cleaning,preprocessing and Feature engineering to create predictive variables
- Exploratory data analysis
- Model training and evaluation with Logistic Regression, XGBoost, and LightGBM
- Optuna Hyperparameter tuning 
- SHAP and LIME Model explainability

## Live Demo

ðŸš€ **[Try the Interactive App](https://credit-risk-model-demo.streamlit.app/)**

The trained LightGBM model is deployed as an interactive web application where you can:
- Generate random credit risk predictions
- Upload CSV files for batch predictions
- View model performance metrics

<!-- ![App Demo](assets/streamlit_demo.gif) -->


## Tech Stack

- Python (refer to requirement.txt for the packages used in this project)
- Duckdb (aggregating and joining multiple csvs)
- Scikit-learn, XGBoost, LightGBM (machine learning )
- SHAP & LIME (model explainability)
- Optuna (Hyperparameter tuning) 
- Streamlit (interactive web application & deployment)

## Quick glance at the results

Target distribution between the features.

![Bar chart](assets/target_dist.png)

Summary bar of major features

![Bar chart](assets/shap_summary_bar.png)

Confusion matrix of LightGBM.

![Confusion matrix](assets/confusion_matrix_lgbm_tuned.png)

ROC curve of LightGBM.

![ROC curve](assets/roc_curve.png)

Top 3 models 

| Model     	         |    AUC-ROC score     |
|----------------------|----------------------|
| LightGBM(tuned)      | 72.57% 	            |
| XGboost  (tuned)     | 72.42% 	            |
| Logistic Regression  | 69.80% 	            |


- ***The final model used is: LightGBM***
- ***Metrics used: Recall, AUC-ROC, AUC-PR, Precision,	F1-score, KS, Gini***


## Model Evaluation Strategy

**Primary Metric: ROC-AUC**
Credit risk data is very imbalanced, so ROC-AUC is best here as it measures how well the model does in separating defaulters from non defaulters

**Supporting Metrics: Precision, Recall, F1**
- **Recall** is critical as missing a high-risk borrower leads to real financial loss.
- **Precision** helps ensure we donâ€™t wrongly reject too many good borrowers
- **F1** balances both precision and recall.


## Lessons Learned and Recommendation 

**What I found:**
- Based on the analysis in this project it was found that loan amount, existing debt ratio, and age were the strongest predictors of default
- Hyperparameter tuning barely helped improve the model performance, for example XGBoost went from 0.722349 to 0.724171 AUC and it took over 30 minutes to train. This suggests that features matter more than tuning
- For imbalanced data, AUC-ROC matters way more than accuracy, and the 0.5 threshold doesn't work (except for logistic regression), the optimal threshold was 0.121

**Recommendations:**
- Recommendation would be to focus more on the loan amount when deciding since they carry the most risk and also accept that precision will be low, you'll reject some good customers to catch defaults

## Limitation and What Can Be Improved
- Low precision means 80% of rejected applicants are false positives (lost customers)
- Hyperparameter tuning with Optuna takes 1+ hours
- Get more data 
- Monitor model performance over time and retrain quarterly

## Repository structure

<details>
  <summary><strong>Repository Structure (click to expand)</strong></summary>

```text

credit-risk-model/
â”œâ”€â”€ assets/                          # Images used in the README 
â”‚   â”œâ”€â”€ confusion_matrix_lgbm_tuned.png
â”‚   â”œâ”€â”€ Credit_img.png
â”‚   â”œâ”€â”€ roc_curve.png
â”‚   â”œâ”€â”€ shap_summary_bar.png
â”‚   â””â”€â”€ target_dist.png
â”‚
â”œâ”€â”€ data/                            # All data (raw, processed, samples)
â”‚   â”œâ”€â”€ data_sample/                 # small samples for quick loading 
â”‚   â”‚   â”œâ”€â”€ application_test_sample.csv
â”‚   â”‚   â”œâ”€â”€ application_train_sample.csv
â”‚   â”‚   â”œâ”€â”€ bureau_balance_sample.csv
â”‚   â”‚   â”œâ”€â”€ bureau_sample.csv
â”‚   â”‚   â”œâ”€â”€ credit_card_balance_sample.csv
â”‚   â”‚   â”œâ”€â”€ installments_payments_sample.csv
â”‚   â”‚   â”œâ”€â”€ POS_CASH_balance_sample.csv
â”‚   â”‚   â””â”€â”€ previous_application_sample.csv
â”‚   â”‚
â”‚   â”œâ”€â”€ processed/                   # cleaned + feature engineered datasets (not tracked in git)
â”‚   â”‚   â”œâ”€â”€ agg_main.csv
â”‚   â”‚   â”œâ”€â”€ cleaned_train.csv
â”‚   â”‚   â”œâ”€â”€ cleaned_val.csv
â”‚   â”‚   â”œâ”€â”€ feature_engineered_val.csv
â”‚   â”‚   â”œâ”€â”€ feature_engineered.csv
â”‚   â”‚   â”œâ”€â”€ target_train.csv
â”‚   â”‚   â””â”€â”€ target_val.csv
â”‚   â”‚
â”‚   â””â”€â”€ raw/                         # original home credit datasets (not tracked in git)
â”‚       â”œâ”€â”€ application_test.csv
â”‚       â”œâ”€â”€ application_train.csv
â”‚       â”œâ”€â”€ bureau_balance.csv
â”‚       â”œâ”€â”€ bureau.csv
â”‚       â”œâ”€â”€ credit_card_balance.csv
â”‚       â”œâ”€â”€ installments_payments.csv
â”‚       â”œâ”€â”€ POS_CASH_balance.csv
â”‚       â”œâ”€â”€ previous_application.csv
â”‚       â””â”€â”€ README.md                # Download instructions
â”‚
â”œâ”€â”€ models/                          # Saved trained models (not tracked in git)
â”‚   â”œâ”€â”€ LightGBM.joblib
â”‚   â”œâ”€â”€ log_reg.joblib
â”‚   â””â”€â”€ XGBoost.joblib
â”‚
â”œâ”€â”€ notebooks/                       # Jupyter notebooks for analysis + modelling + interpretation
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â”œâ”€â”€ 02_modelling.ipynb
â”‚   â””â”€â”€ 03_explainability.ipynb
â”‚
â”œâ”€â”€ results/                         # Generated plots and outputs
â”‚   â”œâ”€â”€ EDA/                         # EDA visualisations
â”‚   â”‚   â”œâ”€â”€ CODE_GENDER_target_relationship.png
â”‚   â”‚   â”œâ”€â”€ CODE_GENDER_value_counts.png
â”‚   â”‚   â”œâ”€â”€ correlation_matrix.png
â”‚   â”‚   â”œâ”€â”€ missing_value_map.png
â”‚   â”‚   â”œâ”€â”€ NAME_CONTRACT_TYPE_target_relationship.png
â”‚   â”‚   â”œâ”€â”€ NAME_CONTRACT_TYPE_value_counts.png
â”‚   â”‚   â”œâ”€â”€ numeric_boxplots.png
â”‚   â”‚   â”œâ”€â”€ numeric_histograms.png
â”‚   â”‚   â”œâ”€â”€ OCCUPATION_TYPE_target_relationship.png
â”‚   â”‚   â”œâ”€â”€ OCCUPATION_TYPE_value_counts.png
â”‚   â”‚   â””â”€â”€ target_dist.png
â”‚   â”‚
â”‚   â””â”€â”€ explainability/              # Model interpretation outputs
â”‚       â”œâ”€â”€ lime_0.png
â”‚       â”œâ”€â”€ lime_1.png
â”‚       â”œâ”€â”€ lime_2.png
â”‚       â”œâ”€â”€ roc_curve.png
â”‚       â”œâ”€â”€ shap_dependence_age_years.png
â”‚       â”œâ”€â”€ shap_dependence_avg_debt_ratio.png
â”‚       â”œâ”€â”€ shap_dependence_CODE_GENDER.png
â”‚       â”œâ”€â”€ shap_dependence_total_credit_requested.png
â”‚       â”œâ”€â”€ shap_dependence_value_of_goods_financed.png
â”‚       â”œâ”€â”€ shap_summary_bar.png
â”‚       â””â”€â”€ shap_summary.png
â”‚
â”œâ”€â”€ src/                             # Python modules
â”‚   â”œâ”€â”€ credit_risk_model/           # Package folder for imports
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ aggregations.py          # Aggregations
â”‚   â”‚   â”œâ”€â”€ config.py                # Paths and constants
â”‚   â”‚   â”œâ”€â”€ data_cleaning.py         # Cleaning + preprocessing logic
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py        # DuckDB ingestion + joins
â”‚   â”‚   â”œâ”€â”€ feat_eng.py              # Feature engineering functions
â”‚   â”‚   â””â”€â”€ model.py                 # Training + evaluation
â”‚   â”‚
â”‚
â”œâ”€â”€ .gitignore                       # Files/folders ignored by git
â”œâ”€â”€ home_credit.duckdb               # DuckDB database file
â”œâ”€â”€ pyproject.toml                   # Build system config 
â”œâ”€â”€ README.md                        # Project overview
â””â”€â”€ requirements.txt                 # Required python packages

